{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests transformers sentence-transformers beautifulsoup4"
      ],
      "metadata": {
        "id": "ZtgrOd4d5iim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web Scraping the Sections"
      ],
      "metadata": {
        "id": "0WnDz6ppkaE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "BASE_URL = \"https://devgan.in\"\n",
        "LAW_TYPE = \"ipc\"\n",
        "MAIN_URL = f\"{BASE_URL}/{LAW_TYPE}/\"\n",
        "\n",
        "# Step 1: Get all chapter links\n",
        "response = requests.get(MAIN_URL)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "chapters = []\n",
        "for row in soup.select(\"table.menu tr\"):\n",
        "    columns = row.find_all(\"td\")\n",
        "    if len(columns) == 2:\n",
        "        chapter_number = columns[0].text.strip()\n",
        "        chapter_title = columns[1].text.strip()\n",
        "        chapter_link = BASE_URL + columns[1].find(\"a\")[\"href\"]\n",
        "        chapters.append((chapter_number, chapter_title, chapter_link))\n",
        "\n",
        "# Step 2: Scrape each chapter's content\n",
        "for chapter_number, chapter_title, chapter_link in chapters:\n",
        "    chapter_response = requests.get(chapter_link)\n",
        "    chapter_soup = BeautifulSoup(chapter_response.text, \"html.parser\")\n",
        "\n",
        "    # Extracting the main content - Modify selector if needed\n",
        "    content_div = chapter_soup.find(\"div\", id=\"content\")\n",
        "\n",
        "    if content_div:\n",
        "        chapter_content = content_div.get_text(separator=\"\\n\", strip=True)\n",
        "    else:\n",
        "        chapter_content = \"Content not found.\"\n",
        "\n",
        "    print(f\"Chapter {chapter_number}: {chapter_title}\")\n",
        "    print(f\"URL: {chapter_link}\")\n",
        "    print(chapter_content)\n",
        "    print(\"\\n\" + \"-\"*100 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "ZDZ8cLAI3qyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Load embedding model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Example text (replace with scraped section text)\n",
        "section_text = \"Whoever does any act with the intention of causing death...\"\n",
        "\n",
        "# Convert text to vector\n",
        "embedding = model.encode(section_text)\n",
        "\n",
        "print(np.array(embedding).shape)  # Output should be (384,) for MiniLM\n"
      ],
      "metadata": {
        "id": "7aIR5OMwBLn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Initialize FAISS index\n",
        "dimension = 384  # Embedding size of the model\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Store embeddings\n",
        "vectors = np.array([embedding], dtype=np.float32)\n",
        "index.add(vectors)\n"
      ],
      "metadata": {
        "id": "aSW-4xhjBUec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "pinecone.init(api_key=\"your_api_key\", environment=\"us-west1-gcp\")\n",
        "\n",
        "index = pinecone.Index(\"law-sections\")\n",
        "\n",
        "# Store vector with metadata\n",
        "index.upsert(vectors=[(\"section_302\", embedding.tolist(), {\"text\": section_text})])\n"
      ],
      "metadata": {
        "id": "6GpJE4G5BZ5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query"
      ],
      "metadata": {
        "id": "iJrXDTSuBdzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the punishment for theft?\"\n",
        "query_embedding = model.encode(query)\n",
        "\n",
        "# FAISS search\n",
        "D, I = index.search(np.array([query_embedding], dtype=np.float32), k=3)\n",
        "print(f\"Top results: {I}\")\n",
        "\n",
        "# Pinecone search\n",
        "results = index.query(query_embedding.tolist(), top_k=3, include_metadata=True)\n",
        "for match in results[\"matches\"]:\n",
        "    print(match[\"metadata\"][\"text\"])\n"
      ],
      "metadata": {
        "id": "dKOm-TajBbzR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}